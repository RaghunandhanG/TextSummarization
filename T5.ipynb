{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"CSV/train.csv\")\n",
    "df_test = pd.read_csv(\"CSV/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. ...</td>\n",
       "      <td>Mr. Smith's getting a check-up, and Doctor Haw...</td>\n",
       "      <td>get a check-up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>#Person1#: Hello Mrs. Parker, how have you bee...</td>\n",
       "      <td>Mrs Parker takes Ricky for his vaccines. Dr. P...</td>\n",
       "      <td>vaccines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>#Person1#: Excuse me, did you see a set of key...</td>\n",
       "      <td>#Person1#'s looking for a set of keys and asks...</td>\n",
       "      <td>find keys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>#Person1#: Why didn't you tell me you had a gi...</td>\n",
       "      <td>#Person1#'s angry because #Person2# didn't tel...</td>\n",
       "      <td>have a girlfriend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>#Person1#: Watsup, ladies! Y'll looking'fine t...</td>\n",
       "      <td>Malik invites Nikki to dance. Nikki agrees if ...</td>\n",
       "      <td>dance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           dialogue  \\\n",
       "0  train_0  #Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. ...   \n",
       "1  train_1  #Person1#: Hello Mrs. Parker, how have you bee...   \n",
       "2  train_2  #Person1#: Excuse me, did you see a set of key...   \n",
       "3  train_3  #Person1#: Why didn't you tell me you had a gi...   \n",
       "4  train_4  #Person1#: Watsup, ladies! Y'll looking'fine t...   \n",
       "\n",
       "                                             summary              topic  \n",
       "0  Mr. Smith's getting a check-up, and Doctor Haw...     get a check-up  \n",
       "1  Mrs Parker takes Ricky for his vaccines. Dr. P...           vaccines  \n",
       "2  #Person1#'s looking for a set of keys and asks...          find keys  \n",
       "3  #Person1#'s angry because #Person2# didn't tel...  have a girlfriend  \n",
       "4  Malik invites Nikki to dance. Nikki agrees if ...              dance  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop([\"id\" , \"topic\"] , inplace=True , axis = 1)\n",
    "df_test.drop([\"id\" , \"topic\"] , inplace=True , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. ...</td>\n",
       "      <td>Mr. Smith's getting a check-up, and Doctor Haw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#Person1#: Hello Mrs. Parker, how have you bee...</td>\n",
       "      <td>Mrs Parker takes Ricky for his vaccines. Dr. P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Person1#: Excuse me, did you see a set of key...</td>\n",
       "      <td>#Person1#'s looking for a set of keys and asks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Person1#: Why didn't you tell me you had a gi...</td>\n",
       "      <td>#Person1#'s angry because #Person2# didn't tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Person1#: Watsup, ladies! Y'll looking'fine t...</td>\n",
       "      <td>Malik invites Nikki to dance. Nikki agrees if ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            dialogue  \\\n",
       "0  #Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. ...   \n",
       "1  #Person1#: Hello Mrs. Parker, how have you bee...   \n",
       "2  #Person1#: Excuse me, did you see a set of key...   \n",
       "3  #Person1#: Why didn't you tell me you had a gi...   \n",
       "4  #Person1#: Watsup, ladies! Y'll looking'fine t...   \n",
       "\n",
       "                                             summary  \n",
       "0  Mr. Smith's getting a check-up, and Doctor Haw...  \n",
       "1  Mrs Parker takes Ricky for his vaccines. Dr. P...  \n",
       "2  #Person1#'s looking for a set of keys and asks...  \n",
       "3  #Person1#'s angry because #Person2# didn't tel...  \n",
       "4  Malik invites Nikki to dance. Nikki agrees if ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Person1#: Ms. Dawson, I need you to take a di...</td>\n",
       "      <td>Ms. Dawson helps #Person1# to write a memo to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#Person1#: Ms. Dawson, I need you to take a di...</td>\n",
       "      <td>In order to prevent employees from wasting tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Person1#: Ms. Dawson, I need you to take a di...</td>\n",
       "      <td>Ms. Dawson takes a dictation for #Person1# abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Person1#: You're finally here! What took so l...</td>\n",
       "      <td>#Person2# arrives late because of traffic jam....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Person1#: You're finally here! What took so l...</td>\n",
       "      <td>#Person2# decides to follow #Person1#'s sugges...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            dialogue  \\\n",
       "0  #Person1#: Ms. Dawson, I need you to take a di...   \n",
       "1  #Person1#: Ms. Dawson, I need you to take a di...   \n",
       "2  #Person1#: Ms. Dawson, I need you to take a di...   \n",
       "3  #Person1#: You're finally here! What took so l...   \n",
       "4  #Person1#: You're finally here! What took so l...   \n",
       "\n",
       "                                             summary  \n",
       "0  Ms. Dawson helps #Person1# to write a memo to ...  \n",
       "1  In order to prevent employees from wasting tim...  \n",
       "2  Ms. Dawson takes a dictation for #Person1# abo...  \n",
       "3  #Person2# arrives late because of traffic jam....  \n",
       "4  #Person2# decides to follow #Person1#'s sugges...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\n",
      "#Person2#: I found it would be a good idea to get a check-up.\n",
      "#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\n",
      "#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\n",
      "#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\n",
      "#Person2#: Ok.\n",
      "#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\n",
      "#Person2#: Yes.\n",
      "#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\n",
      "#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\n",
      "#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\n",
      "#Person2#: Ok, thanks doctor.\n"
     ]
    }
   ],
   "source": [
    "print(df_train[\"dialogue\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\n"
     ]
    }
   ],
   "source": [
    "print(df_train[\"summary\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# Sample train_df DataFrame\n",
    "# train_df = pd.DataFrame({\n",
    "#     \"dialouge\": [\"Input text 1\", \"Input text 2\"],\n",
    "#     \"summary\": [\"Summary 1\", \"Summary 2\"]\n",
    "# })\n",
    "\n",
    "# Convert DataFrame to custom data format\n",
    "custom_data = [\n",
    "    {\"text\": row[\"dialogue\"], \"summary\": row[\"summary\"]}\n",
    "    for index, row in df_train.iterrows()\n",
    "]\n",
    "\n",
    "# Create a Hugging Face Dataset\n",
    "custom_dataset = Dataset.from_dict({\n",
    "    \"text\": [entry[\"text\"] for entry in custom_data],\n",
    "    \"summary\": [entry[\"summary\"] for entry in custom_data]\n",
    "})\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# train_test_split = custom_dataset.train_test_split(test_size=0)\n",
    "\n",
    "# Access the training and testing datasets\n",
    "train_dataset = custom_dataset\n",
    "# test_dataset = train_test_split['test']\n",
    "\n",
    "# Optionally, print out the first few entries to verify\n",
    "# print(train_dataset[:5])\n",
    "# print(test_dataset[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# Sample train_df DataFrame\n",
    "# train_df = pd.DataFrame({\n",
    "#     \"dialouge\": [\"Input text 1\", \"Input text 2\"],\n",
    "#     \"summary\": [\"Summary 1\", \"Summary 2\"]\n",
    "# })\n",
    "\n",
    "# Convert DataFrame to custom data format\n",
    "custom_data = [\n",
    "    {\"text\": row[\"dialogue\"], \"summary\": row[\"summary\"]}\n",
    "    for index, row in df_test.iterrows()\n",
    "]\n",
    "\n",
    "# Create a Hugging Face Dataset\n",
    "custom_dataset = Dataset.from_dict({\n",
    "    \"text\": [entry[\"text\"] for entry in custom_data],\n",
    "    \"summary\": [entry[\"summary\"] for entry in custom_data]\n",
    "})\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# train_test_split = custom_dataset.train_test_split(test_size=0)\n",
    "\n",
    "# Access the training and testing datasets\n",
    "test_dataset = custom_dataset\n",
    "# test_dataset = train_test_split['test']\n",
    "\n",
    "# Optionally, print out the first few entries to verify\n",
    "# print(train_dataset[:5])\n",
    "# print(test_dataset[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Raghunandhan G\\Desktop\\Text Summarization\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12460/12460 [00:05<00:00, 2300.04 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1500/1500 [00:00<00:00, 2391.87 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_tokens = train_dataset.map(preprocess_function, batched=True)\n",
    "test_tokens = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\\n#Person2#: I found it would be a good idea to get a check-up.\\n#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\\n#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\\n#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\\n#Person2#: Ok.\\n#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\\n#Person2#: Yes.\\n#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\\n#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\\n#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\\n#Person2#: Ok, thanks doctor.\", 'summary': \"Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\", 'input_ids': [21603, 10, 1713, 345, 13515, 536, 4663, 10, 2018, 6, 1363, 5, 3931, 5, 27, 31, 51, 7582, 12833, 77, 7, 5, 1615, 33, 25, 270, 469, 58, 1713, 345, 13515, 357, 4663, 10, 27, 435, 34, 133, 36, 3, 9, 207, 800, 12, 129, 3, 9, 691, 18, 413, 5, 1713, 345, 13515, 536, 4663, 10, 2163, 6, 168, 6, 25, 43, 29, 31, 17, 141, 80, 21, 305, 203, 5, 148, 225, 43, 80, 334, 215, 5, 1713, 345, 13515, 357, 4663, 10, 27, 214, 5, 27, 2320, 38, 307, 38, 132, 19, 1327, 1786, 6, 572, 281, 217, 8, 2472, 58, 1713, 345, 13515, 536, 4663, 10, 1548, 6, 8, 200, 194, 12, 1792, 2261, 21154, 19, 12, 253, 91, 81, 135, 778, 5, 264, 653, 12, 369, 44, 709, 728, 3, 9, 215, 21, 39, 293, 207, 5, 1713, 345, 13515, 357, 4663, 10, 8872, 5, 1713, 345, 13515, 536, 4663, 10, 1563, 140, 217, 270, 5, 696, 2053, 11, 11581, 320, 1399, 5, 2321, 3, 9, 1659, 6522, 6, 754, 5, 531, 25, 7269, 6, 1363, 5, 3931, 58, 1713, 345, 13515, 357, 4663, 10, 2163, 5, 1713, 345, 13515, 536, 4663, 10, 14627, 53, 19, 8, 1374, 1137, 13, 5084, 1874, 11, 842, 1994, 6, 25, 214, 5, 148, 310, 225, 10399, 5, 1713, 345, 13515, 357, 4663, 10, 27, 31, 162, 1971, 3986, 13, 648, 6, 68, 27, 131, 54, 31, 17, 1727, 12, 4583, 8, 7386, 5, 1713, 345, 13515, 536, 4663, 10, 1548, 6, 62, 43, 2287, 11, 128, 11208, 24, 429, 199, 5, 27, 31, 195, 428, 25, 72, 251, 274, 25, 1175, 5, 1713, 345, 13515, 357, 4663, 10, 8872, 6, 2049, 2472, 5, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [1363, 5, 3931, 31, 7, 652, 3, 9, 691, 18, 413, 6, 11, 7582, 12833, 77, 7, 7786, 7, 376, 12, 43, 80, 334, 215, 5, 12833, 77, 7, 31, 195, 428, 128, 251, 81, 70, 2287, 11, 11208, 12, 199, 1363, 5, 3931, 10399, 10257, 5, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(train_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Raghunandhan G\\Desktop\\Text Summarization\\.venv\\Lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "  0%|          | 0/10 [27:35<?, ?it/s]\n",
      "  2%|â–         | 122/7790 [42:02<29:10:08, 13.69s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"dialouge_summarization_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=10,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokens,\n",
    "    eval_dataset=test_tokens,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
